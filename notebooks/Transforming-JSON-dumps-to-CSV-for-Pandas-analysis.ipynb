{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transforming goodreads_reviews_dedup.json.gz to CSV\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "from collections import Counter\n",
    "from langdetect import detect\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "import gzip\n",
    "import os\n",
    "\n",
    "data_dir = '/Volumes/Samsung_T5/Data/Book-Reviews/GoodReads/'\n",
    "\n",
    "files = [\n",
    "    #'goodreads_book_authors.json.gz',\n",
    "    'goodreads_reviews_dedup.json.gz',\n",
    "]\n",
    "\n",
    "def detect_lang(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except (LangDetectException, TypeError):\n",
    "        return 'unknown'\n",
    "    \n",
    "def parse_review(review):\n",
    "    review['review_text'] = review['review_text'].replace('\\r', ' ')\n",
    "    review['review_text'] = review['review_text'].replace('\\n', ' ')\n",
    "    review['review_length'] = len(review['review_text'])\n",
    "    review['review_lang'] = detect_lang(review['review_text'])\n",
    "    return review\n",
    "\n",
    "def read_json(data_file):\n",
    "    with gzip.open(data_file, 'rt') as fh:\n",
    "        for line in fh:\n",
    "            yield json.loads(line.strip())\n",
    "            \n",
    "def json_to_csv(json_file, csv_file):\n",
    "    reader = read_json(json_file)\n",
    "    first = next(reader)\n",
    "    headers = list(first.keys())\n",
    "    if 'review_text' in headers:\n",
    "        headers.remove('review_text')\n",
    "        headers.append('review_length')\n",
    "        headers.append('review_lang')\n",
    "        headers.append('review_text')\n",
    "        first = parse_review(first)\n",
    "    with gzip.open(csv_file, 'wt') as fh:\n",
    "        writer = csv.writer(fh, delimiter='\\t')\n",
    "        writer.writerow(headers)\n",
    "        writer.writerow([first[header] if header in first else None for header in headers])\n",
    "        for record in reader:\n",
    "            if 'review_text' in record:\n",
    "                record = parse_review(record)\n",
    "            writer.writerow([record[header] if header in record else None for header in headers])\n",
    "\n",
    "\n",
    "def inspect_fields(data_file):\n",
    "    header_count = Counter()\n",
    "    for record in read_json(data_file):\n",
    "        header_count.update(record.keys())\n",
    "    max_count = max(header_count.values())\n",
    "    min_count = min(header_count.values())\n",
    "    if max_count > min_count:\n",
    "        print('non-equal field counts')\n",
    "        print(header_count)\n",
    "    else:\n",
    "        print('equal field counts')\n",
    "        print(header_count)\n",
    "    return header_count.keys()\n",
    "\n",
    "\n",
    "for filename in files:\n",
    "    if '.json' in filename:\n",
    "        print(f'transforming {filename} to CSV')\n",
    "    else:\n",
    "        print(f'skipping {filename}')\n",
    "        continue\n",
    "    json_file = os.path.join(data_dir, filename)\n",
    "    csv_file = json_file.replace('json', 'csv')\n",
    "\n",
    "    if csv_file != json_file:\n",
    "        #inspect_fields(json_file)\n",
    "        json_to_csv(json_file, csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = os.path.join(data_dir, 'goodreads_book_genres_initial.json.gz')\n",
    "csv_file = json_file.replace('json', 'csv')\n",
    "\n",
    "headers = ['book_id', 'genres']\n",
    "with gzip.open(csv_file, 'wt') as fh:\n",
    "    writer = csv.writer(fh, delimiter='\\t')\n",
    "    writer.writerow(headers)\n",
    "    for ri, record in enumerate(read_json(json_file)):\n",
    "        for genre in record['genres']:\n",
    "            doc = {'book_id': record['book_id'], 'genre': genre}\n",
    "            row = [record['book_id'], genre]\n",
    "            writer.writerow(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 records parsed 113676 rows printed\n",
      "200000 records parsed 227587 rows printed\n",
      "300000 records parsed 342076 rows printed\n",
      "400000 records parsed 456535 rows printed\n",
      "500000 records parsed 570463 rows printed\n",
      "600000 records parsed 684301 rows printed\n",
      "700000 records parsed 798336 rows printed\n",
      "800000 records parsed 912376 rows printed\n",
      "900000 records parsed 1027553 rows printed\n",
      "1000000 records parsed 1141468 rows printed\n",
      "1100000 records parsed 1255976 rows printed\n",
      "1200000 records parsed 1370538 rows printed\n",
      "1300000 records parsed 1484713 rows printed\n",
      "1400000 records parsed 1599219 rows printed\n",
      "1500000 records parsed 1713095 rows printed\n",
      "1600000 records parsed 1827324 rows printed\n",
      "1700000 records parsed 1941476 rows printed\n",
      "1800000 records parsed 2055309 rows printed\n",
      "1900000 records parsed 2169593 rows printed\n",
      "2000000 records parsed 2283752 rows printed\n",
      "2100000 records parsed 2397019 rows printed\n",
      "2200000 records parsed 2510567 rows printed\n",
      "2300000 records parsed 2624920 rows printed\n"
     ]
    }
   ],
   "source": [
    "json_file = os.path.join(data_dir, 'goodreads_books.json.gz')\n",
    "csv_file = json_file.replace('json', 'csv')\n",
    "\n",
    "headers = [\n",
    "    'isbn', 'text_reviews_count', 'country_code', 'language_code', 'asin', 'average_rating', \n",
    "    'author_id', 'publisher', 'num_pages', \n",
    "    'isbn13', 'publication_year', 'book_id', 'ratings_count', 'work_id', 'title', 'title_without_series'\n",
    "]\n",
    "\n",
    "doc_count = 0\n",
    "with gzip.open(csv_file, 'wt') as fh:\n",
    "    writer = csv.writer(fh, delimiter='\\t')\n",
    "    writer.writerow(headers)\n",
    "    for ri, record in enumerate(read_json(json_file)):\n",
    "        for author in record['authors']:\n",
    "            if author['role'].lower() in ['', 'author', 'creator']:\n",
    "                doc = {header: record[header] for header in headers if header in record}\n",
    "                doc['author_id'] = author['author_id']\n",
    "                row = [doc[header] for header in headers]\n",
    "                doc_count += 1\n",
    "                writer.writerow(row)\n",
    "        if (ri+1) % 100000 == 0:\n",
    "            print(ri+1, 'records parsed', doc_count, 'rows printed')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
